import { createContext, useContext, useState, useCallback, useEffect } from 'react';
import { useVoiceRecognition } from '../hooks/useVoiceRecognition';
import { useTextToSpeech } from '../hooks/useTextToSpeech';
import { processVoiceCommand, checkVoiceAvailability, captureScreenshot } from '../services/api/voiceApiClient';

/**
 * Contexto global para el sistema de navegaci√≥n por voz
 * Centraliza el estado y las funciones de voz en toda la aplicaci√≥n
 */
const VoiceContext = createContext(null);

/**
 * Estados posibles del sistema de voz
 */
export const VoiceState = {
  IDLE: 'idle',              // Inactivo, esperando
  LISTENING: 'listening',    // Escuchando al usuario
  PROCESSING: 'processing',  // Procesando comando con IA
  EXECUTING: 'executing',    // Ejecutando acciones
  ERROR: 'error'             // Error ocurri√≥
};

/**
 * Provider del contexto de voz
 */
export function VoiceProvider({ children }) {
  // Hooks de voz con contexto de p√°gina actual
  const voiceRecognition = useVoiceRecognition({
    language: 'es-ES',
    continuous: false,
    interimResults: true,
    context: {
      pathname: window.location.pathname,
      page: window.location.pathname
    }
  });

  // Hook de Text-to-Speech
  const { speak, stop: stopSpeaking, isSpeaking } = useTextToSpeech();

  // Estado global
  const [state, setState] = useState(VoiceState.IDLE);
  const [error, setError] = useState(null);
  const [processing, setProcessing] = useState(false);
  const [isModalOpen, setIsModalOpen] = useState(false);
  const [lastCommand, setLastCommand] = useState(null);
  const [lastResponse, setLastResponse] = useState(null);
  const [commandHistory, setCommandHistory] = useState(() => {
    // Cargar historial desde localStorage al iniciar
    try {
      const saved = localStorage.getItem('voice_command_history');
      return saved ? JSON.parse(saved) : [];
    } catch (error) {
      console.error('[Voice Context] Error cargando historial:', error);
      return [];
    }
  });
  const [historyIndex, setHistoryIndex] = useState(-1); // -1 = no navegando historial
  const [isEnabled, setIsEnabled] = useState(true);

  // Guardar historial en localStorage cuando cambie
  useEffect(() => {
    try {
      localStorage.setItem('voice_command_history', JSON.stringify(commandHistory));
    } catch (error) {
      console.error('[Voice Context] Error guardando historial:', error);
    }
  }, [commandHistory]);

  // Verificar disponibilidad al cargar
  useEffect(() => {
    const availability = checkVoiceAvailability();
    console.log('[Voice Context] Disponibilidad:', availability);

    if (!availability.isFullySupported) {
      setError('Tu navegador no soporta navegaci√≥n por voz completamente');
    }
  }, []);

  // Sincronizar estado con voiceRecognition
  useEffect(() => {
    if (voiceRecognition.isListening) {
      setState(VoiceState.LISTENING);
      setError(null);
    } else if (state === VoiceState.LISTENING) {
      // Si dej√≥ de escuchar y tenemos transcript, procesarlo
      if (voiceRecognition.transcript) {
        handleVoiceCommand(voiceRecognition.transcript);
      } else {
        setState(VoiceState.IDLE);
      }
    }
  }, [voiceRecognition.isListening, voiceRecognition.transcript]);

  // Manejar errores de reconocimiento de voz
  useEffect(() => {
    if (voiceRecognition.error) {
      // Mensajes de error m√°s espec√≠ficos
      const errorMessages = {
        'no-speech': 'No te escuch√©. Por favor, intenta de nuevo.',
        'audio-capture': 'No se pudo acceder al micr√≥fono. Verifica los permisos.',
        'not-allowed': 'Permiso denegado. Habilita el micr√≥fono en la configuraci√≥n del navegador.',
        'network': 'Error de conexi√≥n. Verifica tu internet.',
        'aborted': 'Reconocimiento cancelado.',
        'bad-grammar': 'Error en el procesamiento del audio.',
      };
      
      const errorType = voiceRecognition.error.toLowerCase();
      const specificMessage = errorMessages[errorType] || voiceRecognition.error;
      
      setError(specificMessage);
      setLastResponse(specificMessage);
      setState(VoiceState.ERROR);
    }
  }, [voiceRecognition.error]);

  /**
   * Procesa un comando de voz envi√°ndolo al backend
   */
  const handleVoiceCommand = useCallback(async (transcript) => {
    if (!transcript || transcript.trim() === '') {
      return;
    }

    try {
      console.log('[Voice Context] Procesando comando:', transcript);

      setState(VoiceState.PROCESSING);
      setProcessing(true);
      
      // Capturar screenshot (ahora con filtro de im√°genes para evitar CORS)
      let screenshot = null;
      try {
        screenshot = await captureScreenshot();
        console.log('[Voice Context] Screenshot capturado:', screenshot ? 'S√≠' : 'No');
      } catch (error) {
        console.warn('[Voice Context] Error capturando screenshot, continuando sin √©l:', error);
      }

      // Enviar al backend (con o sin screenshot)
      const response = await processVoiceCommand(
        transcript,
        {
          page: window.location.pathname
        },
        screenshot
      );

      console.log('[Voice Context] Respuesta:', response);

      // Extraer el feedback del usuario de la respuesta
      const feedbackText = response.data?.userFeedback || 'Comando procesado';
      setLastResponse(feedbackText);

      // üîä LEER LA RESPUESTA EN VOZ ALTA
      speak(feedbackText, {
        lang: 'es-ES',
        rate: 1.1, // Velocidad ligeramente m√°s r√°pida
        pitch: 1.0,
        volume: 0.9
      });

      // Agregar a historial
      setCommandHistory(prev => [
        ...prev,
        {
          timestamp: new Date().toISOString(),
          command: transcript,
          response,
          success: response.success
        }
      ].slice(-10)); // Mantener solo los √∫ltimos 10

      if (response.success) {
        setState(VoiceState.EXECUTING);

        // Determinar √©xito de la ejecuci√≥n
        const execution = response.data?.execution;
        const hasSteps = execution && execution.totalSteps > 0;

        // Considerar exitoso si:
        // 1. No hay steps (solo feedback)
        // 2. Execution.success es true
        // 3. No hay steps fallidos (stepsFailed === 0 o undefined)
        // 4. Hay steps completados (stepsCompleted > 0)
        const executionSuccess = execution?.success;
        const hasFailedSteps = execution?.stepsFailed > 0;
        const hasCompletedSteps = execution?.stepsCompleted > 0;
        
        const isSuccessful = !hasSteps ||
                            executionSuccess === true ||
                            (!hasFailedSteps && hasCompletedSteps);

        console.log('[Voice Context] An√°lisis de ejecuci√≥n:', {
          hasSteps,
          executionSuccess,
          stepsCompleted: execution?.stepsCompleted,
          stepsFailed: execution?.stepsFailed,
          hasFailedSteps,
          hasCompletedSteps,
          isSuccessful
        });

        if (isSuccessful) {
          setProcessing(false);
          setTimeout(() => {
            setState(VoiceState.IDLE);
            voiceRecognition.resetTranscript();
          }, 2000);
        } else {
          setProcessing(false);
          setState(VoiceState.IDLE);
          voiceRecognition.resetTranscript();
        }
      } else {
        throw new Error(response.error || 'Error desconocido');
      }

    } catch (error) {
      console.error('[Voice Context] Error:', error);
      
      setProcessing(false);
      const errorMessage = 'Lo siento, hubo un error al procesar tu comando';
      setError(error.message);
      setLastResponse(errorMessage);
      setState(VoiceState.ERROR);

      // üîä LEER EL MENSAJE DE ERROR EN VOZ ALTA
      speak(errorMessage, {
        lang: 'es-ES',
        rate: 1.0,
        pitch: 0.9,
        volume: 0.9
      });

      setTimeout(() => {
        setState(VoiceState.IDLE);
        voiceRecognition.resetTranscript();
      }, 3000);
    }
  }, [voiceRecognition, speak]);

  /**
   * Inicia la escucha de voz (sin modal)
   */
  const startVoiceCommand = useCallback(() => {
    if (!isEnabled) {
      console.warn('[Voice Context] Sistema de voz deshabilitado');
      return;
    }

    if (state !== VoiceState.IDLE) {
      console.warn('[Voice Context] Sistema ocupado, estado:', state);
      return;
    }

    setError(null);
    setIsModalOpen(false); // No abrir modal
    voiceRecognition.startListening();
  }, [isEnabled, state, voiceRecognition]);

  /**
   * Cancela el comando de voz actual
   */
  const cancelVoiceCommand = useCallback(() => {
    voiceRecognition.stopListening();
    setState(VoiceState.IDLE);
    setError(null);
    setIsModalOpen(false);
    voiceRecognition.resetTranscript();
  }, [voiceRecognition]);

  /**
   * Abre el modal de voz
   */
  const openVoiceModal = useCallback(() => {
    setIsModalOpen(true);
    startVoiceCommand();
  }, [startVoiceCommand]);

  /**
   * Cierra el modal de voz
   */
  const closeVoiceModal = useCallback(() => {
    cancelVoiceCommand();
    setIsModalOpen(false);
  }, [cancelVoiceCommand]);

  /**
   * Habilita/deshabilita el sistema de voz
   */
  const toggleVoice = useCallback((enabled) => {
    setIsEnabled(enabled);
    if (!enabled) {
      cancelVoiceCommand();
    }
  }, [cancelVoiceCommand]);

  /**
   * Limpia el historial de comandos
   */
  const clearHistory = useCallback(() => {
    setCommandHistory([]);
    setHistoryIndex(-1);
    localStorage.removeItem('voice_command_history');
  }, []);

  /**
   * Navega en el historial con flechas (‚Üë‚Üì)
   * ‚Üë = comando anterior, ‚Üì = comando siguiente
   */
  const navigateHistory = useCallback((direction) => {
    if (commandHistory.length === 0) return null;

    let newIndex = historyIndex;
    
    if (direction === 'up') {
      // Flecha arriba: ir al comando anterior (m√°s antiguo)
      newIndex = historyIndex + 1;
      if (newIndex >= commandHistory.length) {
        newIndex = commandHistory.length - 1; // No pasar del inicio
      }
    } else if (direction === 'down') {
      // Flecha abajo: ir al comando siguiente (m√°s reciente)
      newIndex = historyIndex - 1;
      if (newIndex < -1) {
        newIndex = -1; // -1 = no navegando
      }
    }

    setHistoryIndex(newIndex);

    // Retornar comando correspondiente (historia en orden inverso)
    if (newIndex === -1) {
      return null; // Volver al estado sin historial
    }

    const historyCommand = commandHistory[commandHistory.length - 1 - newIndex];
    return historyCommand?.command || null;
  }, [commandHistory, historyIndex]);

  // Event listener para navegaci√≥n con flechas
  useEffect(() => {
    const handleKeyDown = (e) => {
      // Solo si el avatar est√° visible y no estamos escribiendo en un input
      if (document.activeElement.tagName === 'INPUT' || 
          document.activeElement.tagName === 'TEXTAREA') {
        return;
      }

      // Solo cuando el sistema est√° IDLE (no procesando)
      if (state !== VoiceState.IDLE) {
        return;
      }

      if (e.key === 'ArrowUp' || e.key === 'ArrowDown') {
        e.preventDefault();

        const direction = e.key === 'ArrowUp' ? 'up' : 'down';
        const command = navigateHistory(direction);

        if (command) {
          console.log('[Voice Context] Historial navegado:', command);
          // Ejecutar comando del historial
          handleVoiceCommand(command);
        }
      }
    };

    window.addEventListener('keydown', handleKeyDown);
    return () => window.removeEventListener('keydown', handleKeyDown);
  }, [state, navigateHistory, handleVoiceCommand]);

  const value = {
    // Estado
    state,
    error,
    isModalOpen,
    lastCommand,
    lastResponse,
    commandHistory,
    historyIndex,
    isEnabled,

    // Hooks
    voiceRecognition,

    // Funciones
    startVoiceCommand,
    cancelVoiceCommand,
    openVoiceModal,
    closeVoiceModal,
    toggleVoice,
    clearHistory,
    navigateHistory,

    // Text-to-Speech
    speak,
    stopSpeaking,
    isSpeaking,

    // Informaci√≥n
    isSupported: voiceRecognition.isSupported,
    isListening: voiceRecognition.isListening,
    isProcessing: state === VoiceState.PROCESSING || state === VoiceState.EXECUTING,
    currentTranscript: voiceRecognition.fullTranscript
  };

  return (
    <VoiceContext.Provider value={value}>
      {children}
    </VoiceContext.Provider>
  );
}

/**
 * Hook para usar el contexto de voz
 */
export function useVoice() {
  const context = useContext(VoiceContext);

  if (!context) {
    throw new Error('useVoice debe usarse dentro de un VoiceProvider');
  }

  return context;
}

export default VoiceContext;
